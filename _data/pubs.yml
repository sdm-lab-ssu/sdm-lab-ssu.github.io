# When making a new entry, copy the commented out entry, paste it, uncomment, and fill out the fields.
# If any of the fields are confusing look at previous examples for guidance.
#- abs: null
#  authors: null
#  award: null
#  bib: null
#  img: null
#  links: {}
#  short_id: null
#  site: null
#  title: null
#  venue: null
#  video_embed: null
#  tags: null
# Current tags for research areas, see the research areas page for more details:
# deform_obj_manip, 3D_afford_obj_manip, multimodal, rl_algs, auto_driving, active_perception, self_sup_rob

- short_id: "ko2025_swevo"
  title: "Metaheuristic-based weight optimization for robust deep reinforcement learning in continuous control"
  authors: "Gwang-Jong Ko, Jaeseok Huh*"
  venue: "Swarm and Evolutionary Computation, 2025"
  site: "https://doi.org/10.1016/j.swevo.2025.101920"    # 제목에 걸 링크
  img: "../img/papers/metaRL.gif"
  abs: >-
    In recent studies, the policy-based deep reinforcement learning (DRL) algorithms have exhibited superior
    performance in addressing continuous control problems, such as machine arms control and robot gait learning.
    However, these algorithms frequently face challenges inherent in gradient descent-based weight optimization
    methods, including susceptibility to local optima, slow learning speeds due to saddle points, approximation
    errors, and suboptimal hyperparameters. This instability leads to significant performance discrepancies among
    agent instances trained under identical settings, which complicates the practical application of reinforcement
    learning. To address this, we propose a metaheuristic-based weight optimization framework designed to mitigate
    learning instability in DRL for continuous control tasks. The proposed framework introduces a two-phase
    optimization process, where an additional search phase using swarm intelligence algorithms is conducted at the
    end of the learning phase utilizing DRL. In numerical experiments, the proposed framework demonstrated superior
    and more stable performance compared to conventional DRL algorithms in robot locomotion tasks.
  bib: |-
    @article{ko2025metaheuristic,
      title={Metaheuristic-based weight optimization for robust deep reinforcement learning in continuous control},
      author={Ko, Gwang-Jong and Huh, Jaeseok},
      journal={Swarm and Evolutionary Computation},
      volume={95},
      pages={101920},
      year={2025},
      publisher={Elsevier}
    }
  # links:
  #   "[DOI]", "https://doi.org/10.1016/j.swevo.2025.101920"
    # - ["PDF", "/assets/papers/ko2025.pdf"]
    # - ["Code", "https://github.com/..."]
  # award: "Best Paper Award"   # 있으면 표시
  tags:
    - reinforcement learning
    - metaheuristic
    - continuous control


- short_id: "kim2025_ida"
  title: "Semi-supervised contrastive learning with decomposition-based data augmentation for time series classification"
  authors: "Dokyun Kim, Sukhyun Cho, Heewoong Chae, Jonghun Park, Jaeseok Huh*"
  venue: "Intelligent Data Analysis"
  site: "https://journals.sagepub.com/doi/abs/10.3233/IDA-240002"
  img: "/img/papers/nnclr-ts-ida2025.svg"
  tags:
    - Time Series
    - Semi-supervised Learning
    - Contrastive Learning
    - Data Augmentation
  abs: >-
    While time series data are prevalent across diverse sectors, data labeling process still remains resource-intensive.
    This results in a scarcity of labeled data for deep learning, emphasizing the importance of semi-supervised learning
    techniques. Applying semi-supervised learning to time series data presents unique challenges due to its inherent temporal
    complexities. Efficient contrastive learning for time series requires specialized methods, particularly in the development
    of tailored data augmentation techniques. In this paper, we propose a single-step, semi-supervised contrastive learning
    framework named nearest neighbor contrastive learning for time series (NNCLR-TS). Specifically, the proposed framework
    incorporates a support set to store representations including their label information, enabling a pseudo-labeling of the
    unlabeled data based on nearby samples in the latent space. Moreover, our framework presents a novel data augmentation
    method, which selectively augments only the trend component of the data, effectively preserving their inherent periodic
    properties and facilitating effective training. For training, we introduce a novel contrastive loss that utilizes the
    nearest neighbors of augmented data for positive and negative representations. By employing our framework, we unlock the
    ability to attain high-quality embeddings and achieve remarkable performance in downstream classification tasks, tailored
    explicitly for time series. Experimental results demonstrate that our method outperforms the state-of-the-art approaches
    across various benchmarks, validating the effectiveness of our proposed method.
  bib: |-
    @article{kim2025ida,
      title={Semi-supervised contrastive learning with decomposition-based data augmentation for time series classification},
      author={Kim, Dokyun and Cho, Sukhyun and Chae, Heewoong and Park, Jonghun and Huh, Jaeseok},
      journal={Intelligent Data Analysis},
      volume={29},
      number={1},
      pages={94--115},
      year={2025},
      publisher={SAGE Publications}
    }

